{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HemanthInjeti/ingetihemanth/blob/main/Lab04_22021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6G99hFkAbkso"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Bangli-P10_gabor.csv\")\n",
        "\n",
        "# Assuming the \"Original Image\" column is the class label, and columns Gabor1 to Gabor32 are features\n",
        "class_label_column = \"Original Image\"\n",
        "feature_columns = df.columns[2:]\n",
        "\n",
        "# Extract features and class labels\n",
        "X = df[feature_columns].values\n",
        "y = df[class_label_column].values\n",
        "\n",
        "# Function to calculate mean and standard deviation for each class\n",
        "def calculate_class_stats(X, y, class_label):\n",
        "    class_indices = np.where(y == class_label)\n",
        "    class_data = X[class_indices]\n",
        "\n",
        "    class_mean = np.mean(class_data, axis=0)\n",
        "    class_std = np.std(class_data, axis=0)\n",
        "\n",
        "    return class_mean, class_std\n",
        "\n",
        "# Function to calculate Euclidean distance between class centroids\n",
        "def calculate_distance(centroid1, centroid2):\n",
        "    return np.linalg.norm(centroid1 - centroid2)\n",
        "\n",
        "# Get unique class labels\n",
        "unique_labels = np.unique(y)\n",
        "\n",
        "# Choose two classes for evaluation\n",
        "class_label1 = unique_labels[0]  # Use the actual numerical label for the \"Original Image\" column\n",
        "class_label2 = unique_labels[1]  # Use the actual numerical label for the other class\n",
        "\n",
        "# Calculate mean and standard deviation for each class\n",
        "centroid1, std1 = calculate_class_stats(X, y, class_label1)\n",
        "centroid2, std2 = calculate_class_stats(X, y, class_label2)\n",
        "\n",
        "# Calculate Euclidean distance between class centroids\n",
        "distance_between_classes = calculate_distance(centroid1, centroid2)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Mean vector for class {class_label1}: {centroid1}\")\n",
        "print(f\"Standard deviation vector for class {class_label1}: {std1}\")\n",
        "print()\n",
        "print(f\"Mean vector for class {class_label2}: {centroid2}\")\n",
        "print(f\"Standard deviation vector for class {class_label2}: {std2}\")\n",
        "print()\n",
        "print(f\"Distance between class centroids: {distance_between_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Bangli-P10_gabor.csv\")\n",
        "\n",
        "# Choose the feature for analysis (replace 'Original Image' with the actual column name)\n",
        "feature_name = 'Original Image'\n",
        "feature_data = df[feature_name].values\n",
        "\n",
        "# Plot the histogram\n",
        "plt.hist(feature_data, bins=10, color='blue', edgecolor='black', alpha=0.7)\n",
        "plt.title(f'Histogram of {feature_name}')\n",
        "plt.xlabel(feature_name)\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Calculate mean and variance\n",
        "mean_value = np.mean(feature_data)\n",
        "variance_value = np.var(feature_data)\n",
        "\n",
        "print(f\"Mean of {feature_name}: {mean_value}\")\n",
        "print(f\"Variance of {feature_name}: {variance_value}\")"
      ],
      "metadata": {
        "id": "_F2U_Zi9zS-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import minkowski\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Bangli-P10_gabor.csv\")\n",
        "\n",
        "# Choose any two feature vectors (replace 0 and 1 with the indices of the vectors you want to compare)\n",
        "vector1 = df.iloc[0, 2:].values\n",
        "vector2 = df.iloc[1, 2:].values\n",
        "\n",
        "# Calculate Minkowski distances for varying values of r from 1 to 10\n",
        "r_values = np.arange(1, 11)\n",
        "distances = [minkowski(vector1, vector2, p=r) for r in r_values]\n",
        "\n",
        "# Plot the distances\n",
        "plt.plot(r_values, distances, marker='o', linestyle='-')\n",
        "plt.title('Minkowski Distance vs. r')\n",
        "plt.xlabel('r')\n",
        "plt.ylabel('Minkowski Distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DylMxX2JzTK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Bangli-P10_gabor.csv\")\n",
        "\n",
        "# Extract features and class labels\n",
        "X = df.iloc[:, 2:].values  # Assuming columns 3 to 33 are features\n",
        "y = df.iloc[:, 1].values    # Assuming column 2 is the class label\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "id": "gGi7OLaezTe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data_path = \"/content/drive/MyDrive/Bangli-P10_gabor.csv\"  # Replace with the actual path to your dataset\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Extract features and class labels\n",
        "X = df.iloc[:, 1:].values  # Assuming columns 2 to 32 are features\n",
        "y = df.iloc[:, 0].values    # Assuming column 1 is the class label\n",
        "\n",
        "# Choose the class labels for classification\n",
        "class_label1 = 227\n",
        "class_label2 = 226\n",
        "\n",
        "# Select rows corresponding to the chosen classes\n",
        "class_data = df[(df['Original Image'] == class_label1) | (df['Original Image'] == class_label2)]\n",
        "\n",
        "# Check if both class labels are present\n",
        "if len(class_data[class_data['Original Image'] == class_label1]) > 0 and len(class_data[class_data['Original Image'] == class_label2]) > 0:\n",
        "    # Features and class labels for the chosen classes\n",
        "    X_selected = class_data.iloc[:, 1:].values\n",
        "    y_selected = class_data.iloc[:, 0].values\n",
        "\n",
        "    # Split the dataset into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Create a kNN classifier with k=3\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "    # Train the classifier on the training set\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "    # Calculate and print accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy of kNN classifier with k=3: {accuracy}\")\n",
        "\n",
        "else:\n",
        "    print(\"One or both of the specified class labels are not present in the selected subset.\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Kexjhh0dzg6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'YourDatasetPath' with the actual path)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Bangli-P10_gabor.csv\")\n",
        "\n",
        "# Assuming class labels are in the second column\n",
        "class_label1 = 'bad'\n",
        "class_label2 = 'medium'\n",
        "\n",
        "# Select rows corresponding to the chosen classes\n",
        "class_data = df[(df.iloc[:, 1] == class_label1) | (df.iloc[:, 1] == class_label2)]\n",
        "\n",
        "# Features and class labels for the chosen classes\n",
        "X_selected = class_data.iloc[:, 2:-1].values\n",
        "y_selected = class_data.iloc[:, 1].values\n",
        "\n",
        "# Print the size of the selected dataset\n",
        "print(f\"Size of the selected dataset: {X_selected.shape[0]} samples\")\n",
        "\n",
        "# Check if there are enough samples for splitting\n",
        "if X_selected.shape[0] > 0:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Vary k from 1 to 11\n",
        "    k_values = np.arange(1, 12)\n",
        "    accuracy_nn = []  # to store accuracy for NN classifier\n",
        "    accuracy_knn3 = []  # to store accuracy for kNN classifier with k=3\n",
        "\n",
        "    for k in k_values:\n",
        "        # NN classifier\n",
        "        nn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "        nn_classifier.fit(X_train, y_train)\n",
        "        y_pred_nn = nn_classifier.predict(X_test)\n",
        "        accuracy_nn.append(accuracy_score(y_test, y_pred_nn))\n",
        "\n",
        "        # kNN classifier with k=3\n",
        "        knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn_classifier.fit(X_train, y_train)\n",
        "        y_pred_knn3 = knn_classifier.predict(X_test)\n",
        "        accuracy_knn3.append(accuracy_score(y_test, y_pred_knn3))\n",
        "\n",
        "    # Plot the results\n",
        "    plt.plot(k_values, accuracy_nn, label='NN (k varying)')\n",
        "    plt.plot(k_values, accuracy_knn3, label='kNN (k=3)')\n",
        "    plt.title('Accuracy Comparison for NN and kNN (k=3)')\n",
        "    plt.xlabel('k')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Insufficient samples for splitting. Please check your dataset.\")"
      ],
      "metadata": {
        "id": "UFiPb0xDzhHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Bangli-P10_gabor.csv\")\n",
        "\n",
        "# Explore unique values in 'Original Image' column\n",
        "unique_values = df['Original Image'].unique()\n",
        "print(\"Unique values in 'Original Image' column:\", unique_values)\n",
        "\n",
        "# Choose any two unique values for binary classification\n",
        "class_label1 = unique_values[0]\n",
        "class_label2 = unique_values[1]\n",
        "\n",
        "# Select rows corresponding to the chosen classes\n",
        "class_data = df[(df['Original Image'] == class_label1) | (df['Original Image'] == class_label2)]\n",
        "\n",
        "# Features and class labels for the chosen classes\n",
        "X_selected = class_data.iloc[:, 1:-1].values\n",
        "y_selected = class_data.iloc[:, -1].values\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a kNN classifier with k=3\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Train the classifier on the training set\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on training set\n",
        "y_train_pred = knn_classifier.predict(X_train)\n",
        "\n",
        "# Predictions on test set\n",
        "y_test_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Confusion matrix for training set\n",
        "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
        "print(\"Confusion Matrix (Training Set):\")\n",
        "print(conf_matrix_train)\n",
        "\n",
        "# Confusion matrix for test set\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "print(\"\\nConfusion Matrix (Test Set):\")\n",
        "print(conf_matrix_test)\n",
        "\n",
        "# Precision, Recall, and F1-Score for training set\n",
        "precision_train = precision_score(y_train, y_train_pred, average='weighted')  # Use 'weighted' for multi-class\n",
        "recall_train = recall_score(y_train, y_train_pred, average='weighted')\n",
        "f1_score_train = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "# Precision, Recall, and F1-Score for test set\n",
        "precision_test = precision_score(y_test, y_test_pred, average='weighted')  # Use 'weighted' for multi-class\n",
        "recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
        "f1_score_test = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "# Print performance metrics\n",
        "print(\"\\nPerformance Metrics (Training Set):\")\n",
        "print(f\"Precision: {precision_train}\")\n",
        "print(f\"Recall: {recall_train}\")\n",
        "print(f\"F1-Score: {f1_score_train}\")\n",
        "\n",
        "print(\"\\nPerformance Metrics (Test Set):\")\n",
        "print(f\"Precision: {precision_test}\")\n",
        "print(f\"Recall: {recall_test}\")\n",
        "print(f\"F1-Score: {f1_score_test}\")"
      ],
      "metadata": {
        "id": "TpGTPR-fzvyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}